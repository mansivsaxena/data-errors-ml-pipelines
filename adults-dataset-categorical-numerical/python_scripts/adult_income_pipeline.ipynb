{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {
    "id": "0"
   },
   "outputs": [],
   "source": [
    "pip install py-AutoClean matplotlib datasets cleanlab scikit-learn jenga ftfy pandas numpy setuptools ucimlrepo category_encoders -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {
    "id": "1"
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "sys.path.append(os.path.abspath(\"..\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2",
   "metadata": {
    "id": "2"
   },
   "source": [
    "## Load original data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {
    "id": "3"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from AutoClean import AutoClean\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from sklearn.ensemble import HistGradientBoostingClassifier\n",
    "from sklearn.utils import resample\n",
    "\n",
    "df = pd.read_csv(\"adult_for_manual_edit.csv\")\n",
    "\n",
    "numeric_features = ['age', 'education-num', 'capital-gain', 'capital-loss', 'hours-per-week']\n",
    "def resample_df(df):\n",
    "    target_column = df.columns[-1]\n",
    "    X = df.drop(columns=[target_column]).copy()\n",
    "    y = df[[target_column]].copy()\n",
    "\n",
    "    train = X.copy()\n",
    "    train['income'] = y\n",
    "\n",
    "    class_1 = train[train['income'] == '<=50K']\n",
    "    class_2 = train[train['income'] == '>50K']\n",
    "\n",
    "    class_1_resampled = resample(class_1,\n",
    "                                replace=False,\n",
    "                                n_samples=10000,\n",
    "                                random_state=42)\n",
    "\n",
    "    class_2_resampled = resample(class_2,\n",
    "                                replace=False,\n",
    "                                n_samples=10000,\n",
    "                                random_state=42)\n",
    "\n",
    "    df_balanced = pd.concat([class_1_resampled, class_2_resampled]).sample(frac=1, random_state=42)\n",
    "    X = df_balanced.drop(columns=['income'])\n",
    "    y = df_balanced['income']\n",
    "\n",
    "    return X, y\n",
    "\n",
    "X, y = resample_df(df)\n",
    "\n",
    "categorical_features = ['workclass', 'marital-status', 'occupation', 'relationship', 'race', 'sex']\n",
    "\n",
    "numeric_transformer = StandardScaler()\n",
    "categorical_transformer = OneHotEncoder(handle_unknown='ignore')\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numeric_features),\n",
    "        ('cat', categorical_transformer, categorical_features)\n",
    "    ],\n",
    "    sparse_threshold=0\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4",
   "metadata": {
    "id": "4"
   },
   "source": [
    "## Train - Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {
    "id": "5"
   },
   "outputs": [],
   "source": [
    "clf = Pipeline(steps=[\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('classifier', LogisticRegression(\n",
    "            random_state=42,\n",
    "            class_weight='balanced'\n",
    "        ))\n",
    "    ])\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "y_pred = clf.predict(X_test)\n",
    "accuracy_reg_og=accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy on CSV: {accuracy_reg_og:.4f}\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6",
   "metadata": {
    "id": "6"
   },
   "source": [
    "## Corrupt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {
    "id": "7"
   },
   "outputs": [],
   "source": [
    "import src.corruption.inject as inject\n",
    "\n",
    "X_copy = X.copy()\n",
    "\n",
    "numeric_features = ['age', 'education-num', 'capital-gain', 'capital-loss', 'hours-per-week']\n",
    "X_copy[numeric_features] = X_copy[numeric_features].apply(pd.to_numeric, errors='coerce')\n",
    "\n",
    "def all_numerical_corruptions_with_y(X, y, numeric_columns=None):\n",
    "    X = X.copy()\n",
    "    if isinstance(y, pd.Series):\n",
    "        y = y.to_frame(name=y.name or 'income')\n",
    "    df = pd.concat([X, y], axis=1)\n",
    "    y_name = y.columns[0]\n",
    "\n",
    "    if numeric_columns is None:\n",
    "        numeric_columns = [\n",
    "            c for c in X.columns if pd.api.types.is_numeric_dtype(X[c])\n",
    "        ]\n",
    "\n",
    "    df_corrupted = inject.all_numerical_corruptions(\n",
    "        df, columns=numeric_columns\n",
    "    )\n",
    "    df_corrupted = df_corrupted[df.columns]\n",
    "\n",
    "    X_corrupted = df_corrupted.drop(columns=[y_name])\n",
    "    y_corrupted = df_corrupted[y_name]\n",
    "\n",
    "    return X_corrupted, y_corrupted\n",
    "\n",
    "X_corrupted, y_corrupted = all_numerical_corruptions_with_y(X_copy, y, numeric_features)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_corrupted.fillna('0'), y_corrupted, test_size=0.3, random_state=42)\n",
    "\n",
    "clf.fit(X_train, y_train.values.ravel())\n",
    "y_pred = clf.predict(X_test)\n",
    "accuracy_reg_cor=accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy_reg_cor:.4f}\")\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {
    "id": "8"
   },
   "outputs": [],
   "source": [
    "shifted = inject.category_shift(X_corrupted, columns=categorical_features)\n",
    "typos = inject.category_typo(shifted, columns=categorical_features)\n",
    "\n",
    "for col in categorical_features:\n",
    "    typos[col] = typos[col].astype(\"object\")\n",
    "\n",
    "X_corrupted = inject.missing_values(typos, categorical_features, fraction=0.25)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_corrupted.fillna('0'), y_corrupted, test_size=0.3, random_state=42)\n",
    "\n",
    "clf.fit(X_train, y_train.values.ravel())\n",
    "y_pred = clf.predict(X_test)\n",
    "accuracy_reg_cat=accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(f\"Accuracy: {accuracy_reg_cat:.4f}\")\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9",
   "metadata": {
    "id": "9"
   },
   "source": [
    "### Clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {
    "id": "10"
   },
   "outputs": [],
   "source": [
    "X, y = X_corrupted, y_corrupted\n",
    "from src.corruption import clean_num\n",
    "\n",
    "numeric_features = ['age', 'education-num', 'capital-gain', 'capital-loss', 'hours-per-week']\n",
    "X_clean_noisy_removed, y_clean_noisy_removed = clean_num.run_num_clean(numeric_features, X, y, clf)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_clean_noisy_removed, y_clean_noisy_removed, test_size=0.3, random_state=42)\n",
    "\n",
    "clf.fit(X_train, y_train.values.ravel())\n",
    "y_pred = clf.predict(X_test)\n",
    "accuracy_reg_cl=accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(f\"Accuracy: {accuracy_reg_cl:.4f}\")\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {
    "id": "11"
   },
   "outputs": [],
   "source": [
    "X_clean_noisy_removed, y_clean_noisy_removed = clean_num.run_num_clean(numeric_features, X, y, clf, True)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_clean_noisy_removed, y_clean_noisy_removed, test_size=0.3, random_state=42)\n",
    "\n",
    "clf.fit(X_train, y_train.values.ravel())\n",
    "y_pred = clf.predict(X_test)\n",
    "accuracy_reg_cleanlab=accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(len(X))\n",
    "print(f\"Accuracy cleanlab: {accuracy_reg_cleanlab:.4f}\")\n",
    "print(\"Dropped \", len(X_corrupted) - len(X_clean_noisy_removed))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12",
   "metadata": {
    "id": "12"
   },
   "source": [
    "## Train - HistGradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {
    "id": "13"
   },
   "outputs": [],
   "source": [
    "clf = Pipeline(steps=[\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('classifier', HistGradientBoostingClassifier(\n",
    "            random_state=42,\n",
    "            class_weight='balanced'\n",
    "        ))\n",
    "    ])\n",
    "\n",
    "X, y = resample_df(df)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "y_pred = clf.predict(X_test)\n",
    "accuracy_gb_og=accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy on CSV: {accuracy_gb_og:.4f}\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14",
   "metadata": {
    "id": "14"
   },
   "source": [
    "Corrupt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {
    "id": "15"
   },
   "outputs": [],
   "source": [
    "X[numeric_features] = X[numeric_features].apply(pd.to_numeric, errors='coerce')\n",
    "X_corrupted, y_corrupted = all_numerical_corruptions_with_y(X, y, numeric_features)\n",
    "shifted = inject.category_shift(X_corrupted, columns=categorical_features)\n",
    "typos = inject.category_typo(shifted, columns=categorical_features)\n",
    "\n",
    "for col in categorical_features:\n",
    "    typos[col] = typos[col].astype(\"object\")\n",
    "\n",
    "X_corrupted = inject.missing_values(typos, categorical_features, fraction=0.5)\n",
    "X_corrupted = inject.category_default(X_corrupted, categorical_features)\n",
    "clf.fit(X_corrupted, y_corrupted.values.ravel())\n",
    "y_pred = clf.predict(X_test)\n",
    "accuracy_gb_cor=accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(f\"Accuracy: {accuracy_gb_cor:.4f}\")\n",
    "print(\"\\nClassification Report:\", classification_report(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16",
   "metadata": {
    "id": "16"
   },
   "source": [
    "Clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {
    "id": "17"
   },
   "outputs": [],
   "source": [
    "X_clean_noisy_removed, y_clean_noisy_removed = clean_num.run_num_clean(numeric_features, X_corrupted, y_corrupted, clf)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_clean_noisy_removed, y_clean_noisy_removed, test_size=0.3, random_state=42)\n",
    "\n",
    "clf.fit(X_train, y_train.values.ravel())\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "accuracy_gb_cl=accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(f\"Accuracy: {accuracy_gb_cl:.4f}\")\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {
    "id": "18"
   },
   "outputs": [],
   "source": [
    "\n",
    "X_clean_noisy_removed, y_clean_noisy_removed = clean_num.run_num_clean(numeric_features, X_corrupted, y_corrupted, clf, True)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_clean_noisy_removed, y_clean_noisy_removed, test_size=0.3, random_state=42)\n",
    "\n",
    "clf.fit(X_train, y_train.values.ravel())\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "accuracy_gb_cleanlab=accuracy_score(y_test, y_pred)\n",
    "print(len(X_corrupted))\n",
    "print(\"Dropped \", len(X_corrupted) - len(X_clean_noisy_removed))\n",
    "print(f\"Accuracy: {accuracy_gb_cleanlab:.4f}\")\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19",
   "metadata": {
    "id": "19"
   },
   "source": [
    "Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20",
   "metadata": {
    "id": "20"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "logreg_acc=[accuracy_reg_og, accuracy_reg_cat, accuracy_reg_cl, accuracy_reg_cleanlab]\n",
    "histgb_acc=[accuracy_gb_og, accuracy_gb_cor, accuracy_gb_cl, accuracy_gb_cleanlab]\n",
    "labels = [\n",
    "    \"Clean\",\n",
    "    \"Corrupted\",\n",
    "    \"Cleaned\\n(no Cleanlab)\",\n",
    "    \"Cleaned\\n(Cleanlab)\",\n",
    "]\n",
    "\n",
    "x = np.arange(len(labels))\n",
    "width = 0.3\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "ax.bar(x - width/2, logreg_acc, width, label=\"Logistic Regression\")\n",
    "ax.bar(x + width/2, histgb_acc, width, label=\"HistGradientBoosting\")\n",
    "\n",
    "ax.set_ylabel(\"Accuracy\")\n",
    "ax.set_title(\"Effect of Corruption and Cleaning on Model Accuracy\")\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(labels)\n",
    "ax.set_ylim(0, 1)\n",
    "ax.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21",
   "metadata": {
    "id": "21"
   },
   "source": [
    "## Appendix: manual data malformation\n",
    "\n",
    "This section was used previously to generate a big batch of corruptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22",
   "metadata": {
    "id": "22"
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import csv\n",
    "import pandas as pd\n",
    "\n",
    "input_csv = \"adult_for_manual_edit.csv\"\n",
    "output_csv = \"adult_corrupted_text_2.csv\"\n",
    "\n",
    "fraction_corrupt = 0.1\n",
    "chars_to_inject = ['#','@','!','x','a']\n",
    "negate_fraction = 0.1\n",
    "\n",
    "with open(input_csv, newline='', encoding='utf-8') as f:\n",
    "    reader = list(csv.reader(f))\n",
    "    header = reader[0]\n",
    "    rows = reader[1:]\n",
    "\n",
    "col_to_idx = {col: i for i, col in enumerate(header)}\n",
    "print(col_to_idx)\n",
    "\n",
    "for row in rows:\n",
    "    for col_name in numeric_features:\n",
    "        try:\n",
    "            col_idx = col_to_idx[col_name]\n",
    "            cell = row[col_idx]\n",
    "            val = float(cell)\n",
    "        except:\n",
    "            continue\n",
    "\n",
    "        # Negate some values\n",
    "        if random.random() < negate_fraction:\n",
    "            val = -abs(val)\n",
    "\n",
    "        # Multiply by random factor\n",
    "        if random.random() < fraction_corrupt:\n",
    "            factor = random.uniform(0.5, 10.0)\n",
    "            val = val * factor\n",
    "\n",
    "        # Replace some with '?'\n",
    "        if random.random() < fraction_corrupt:\n",
    "            row[col_idx] = '?'\n",
    "            continue \n",
    "\n",
    "        # Inject random char\n",
    "        if random.random() < fraction_corrupt:\n",
    "            row[col_idx] = str(val) + random.choice(chars_to_inject)\n",
    "        else:\n",
    "            row[col_idx] = str(val)\n",
    "\n",
    "for row in rows:\n",
    "    for col_idx in categorical_features:\n",
    "        if random.random() < fraction_corrupt:\n",
    "            col_idx = col_to_idx[col_idx]\n",
    "            val = str(row[col_idx])\n",
    "            n_chars = random.choice([1,2])\n",
    "            for _ in range(n_chars):\n",
    "                pos = random.randint(0, len(val))\n",
    "                val = val[:pos] + random.choice(chars_to_inject) + val[pos:]\n",
    "            row[col_idx] = val\n",
    "\n",
    "with open(output_csv, 'w', newline='', encoding='utf-8') as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow(header)\n",
    "    writer.writerows(rows)\n",
    "\n",
    "df_corrupt = pd.read_csv(output_csv)\n",
    "\n",
    "y = df_corrupt['income']\n",
    "X = df_corrupt.drop(columns=['income'])\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "ipykernel",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
