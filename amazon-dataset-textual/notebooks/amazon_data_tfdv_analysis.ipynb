{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "runtime_attributes": {
        "runtime_version": "2025.07"
      }
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## TFDV Analysis on Baseline vs Corrupted Data"
      ],
      "metadata": {
        "id": "0mMptiWzeO6B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade pip\n",
        "\n",
        "!pip install \\\n",
        "  tensorflow==2.15.1 \\\n",
        "  tensorflow-metadata==1.15.0 \\\n",
        "  tensorflow-data-validation==1.15.1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "collapsed": true,
        "id": "wb40lgJpeTZR",
        "outputId": "852edf84-19ac-46c3-ba0f-670bb43d02c2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pip in /usr/local/lib/python3.11/dist-packages (24.1.2)\n",
            "Collecting pip\n",
            "  Downloading pip-26.0-py3-none-any.whl.metadata (4.7 kB)\n",
            "Downloading pip-26.0-py3-none-any.whl (1.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pip\n",
            "  Attempting uninstall: pip\n",
            "    Found existing installation: pip 24.1.2\n",
            "    Uninstalling pip-24.1.2:\n",
            "      Successfully uninstalled pip-24.1.2\n",
            "Successfully installed pip-26.0\n",
            "Collecting tensorflow==2.15.1\n",
            "  Downloading tensorflow-2.15.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.2 kB)\n",
            "Collecting tensorflow-metadata==1.15.0\n",
            "  Downloading tensorflow_metadata-1.15.0-py3-none-any.whl.metadata (2.4 kB)\n",
            "Collecting tensorflow-data-validation==1.15.1\n",
            "  Downloading tensorflow_data_validation-1.15.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (18 kB)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.15.1) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.15.1) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=23.5.26 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.15.1) (25.2.10)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.15.1) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.15.1) (0.2.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.15.1) (3.14.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.15.1) (18.1.1)\n",
            "Collecting ml-dtypes~=0.3.1 (from tensorflow==2.15.1)\n",
            "  Downloading ml_dtypes-0.3.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (20 kB)\n",
            "Collecting numpy<2.0.0,>=1.23.5 (from tensorflow==2.15.1)\n",
            "  Downloading numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.15.1) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.15.1) (24.2)\n",
            "Collecting protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 (from tensorflow==2.15.1)\n",
            "  Downloading protobuf-4.25.8-cp37-abi3-manylinux2014_x86_64.whl.metadata (541 bytes)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.15.1) (75.2.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.15.1) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.15.1) (3.1.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.15.1) (4.14.1)\n",
            "Collecting wrapt<1.15,>=1.11.0 (from tensorflow==2.15.1)\n",
            "  Downloading wrapt-1.14.2-cp311-cp311-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl.metadata (6.5 kB)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.15.1) (0.37.1)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.15.1) (1.73.1)\n",
            "Collecting tensorboard<2.16,>=2.15 (from tensorflow==2.15.1)\n",
            "  Downloading tensorboard-2.15.2-py3-none-any.whl.metadata (1.7 kB)\n",
            "Collecting tensorflow-estimator<2.16,>=2.15.0 (from tensorflow==2.15.1)\n",
            "  Downloading tensorflow_estimator-2.15.0-py2.py3-none-any.whl.metadata (1.3 kB)\n",
            "Collecting keras<2.16,>=2.15.0 (from tensorflow==2.15.1)\n",
            "  Downloading keras-2.15.0-py3-none-any.whl.metadata (2.4 kB)\n",
            "Requirement already satisfied: googleapis-common-protos<2,>=1.56.4 in /usr/local/lib/python3.11/dist-packages (from tensorflow-metadata==1.15.0) (1.70.0)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow-data-validation==1.15.1) (1.5.1)\n",
            "Collecting pandas<2,>=1.0 (from tensorflow-data-validation==1.15.1)\n",
            "  Downloading pandas-1.5.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\n",
            "Collecting pyarrow<11,>=10 (from tensorflow-data-validation==1.15.1)\n",
            "  Downloading pyarrow-10.0.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.0 kB)\n",
            "Collecting pyfarmhash<0.4,>=0.2.2 (from tensorflow-data-validation==1.15.1)\n",
            "  Downloading pyfarmhash-0.3.2.tar.gz (99 kB)\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting tfx-bsl<1.16,>=1.15.1 (from tensorflow-data-validation==1.15.1)\n",
            "  Downloading tfx_bsl-1.15.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\n",
            "Collecting apache-beam<3,>=2.53 (from apache-beam[gcp]<3,>=2.53; python_version >= \"3.11\"->tensorflow-data-validation==1.15.1)\n",
            "  Downloading apache_beam-2.71.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (21 kB)\n",
            "Requirement already satisfied: cryptography<48.0.0,>=39.0.0 in /usr/local/lib/python3.11/dist-packages (from apache-beam<3,>=2.53->apache-beam[gcp]<3,>=2.53; python_version >= \"3.11\"->tensorflow-data-validation==1.15.1) (43.0.3)\n",
            "Collecting envoy-data-plane<0.3.0 (from apache-beam<3,>=2.53->apache-beam[gcp]<3,>=2.53; python_version >= \"3.11\"->tensorflow-data-validation==1.15.1)\n",
            "  Downloading envoy_data_plane-0.2.6-py3-none-any.whl.metadata (3.4 kB)\n",
            "Collecting fastavro<2,>=0.23.6 (from apache-beam<3,>=2.53->apache-beam[gcp]<3,>=2.53; python_version >= \"3.11\"->tensorflow-data-validation==1.15.1)\n",
            "  Downloading fastavro-1.12.1-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (5.8 kB)\n",
            "Collecting fasteners<1.0,>=0.3 (from apache-beam<3,>=2.53->apache-beam[gcp]<3,>=2.53; python_version >= \"3.11\"->tensorflow-data-validation==1.15.1)\n",
            "  Downloading fasteners-0.20-py3-none-any.whl.metadata (4.8 kB)\n",
            "Collecting grpcio<2.0,>=1.24.3 (from tensorflow==2.15.1)\n",
            "  Downloading grpcio-1.65.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.3 kB)\n",
            "Requirement already satisfied: httplib2<0.23.0,>=0.8 in /usr/local/lib/python3.11/dist-packages (from apache-beam<3,>=2.53->apache-beam[gcp]<3,>=2.53; python_version >= \"3.11\"->tensorflow-data-validation==1.15.1) (0.22.0)\n",
            "Collecting jsonpickle<4.0.0,>=3.0.0 (from apache-beam<3,>=2.53->apache-beam[gcp]<3,>=2.53; python_version >= \"3.11\"->tensorflow-data-validation==1.15.1)\n",
            "  Downloading jsonpickle-3.4.2-py3-none-any.whl.metadata (8.1 kB)\n",
            "Collecting objsize<0.8.0,>=0.6.1 (from apache-beam<3,>=2.53->apache-beam[gcp]<3,>=2.53; python_version >= \"3.11\"->tensorflow-data-validation==1.15.1)\n",
            "  Downloading objsize-0.7.1-py3-none-any.whl.metadata (12 kB)\n",
            "Collecting pymongo<5.0.0,>=3.8.0 (from apache-beam<3,>=2.53->apache-beam[gcp]<3,>=2.53; python_version >= \"3.11\"->tensorflow-data-validation==1.15.1)\n",
            "  Downloading pymongo-4.16.0-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (10.0 kB)\n",
            "Requirement already satisfied: proto-plus<2,>=1.7.1 in /usr/local/lib/python3.11/dist-packages (from apache-beam<3,>=2.53->apache-beam[gcp]<3,>=2.53; python_version >= \"3.11\"->tensorflow-data-validation==1.15.1) (1.26.1)\n",
            "Requirement already satisfied: python-dateutil<3,>=2.8.0 in /usr/local/lib/python3.11/dist-packages (from apache-beam<3,>=2.53->apache-beam[gcp]<3,>=2.53; python_version >= \"3.11\"->tensorflow-data-validation==1.15.1) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2018.3 in /usr/local/lib/python3.11/dist-packages (from apache-beam<3,>=2.53->apache-beam[gcp]<3,>=2.53; python_version >= \"3.11\"->tensorflow-data-validation==1.15.1) (2025.2)\n",
            "Collecting requests<3.0.0,>=2.32.4 (from apache-beam<3,>=2.53->apache-beam[gcp]<3,>=2.53; python_version >= \"3.11\"->tensorflow-data-validation==1.15.1)\n",
            "  Downloading requests-2.32.5-py3-none-any.whl.metadata (4.9 kB)\n",
            "Requirement already satisfied: sortedcontainers>=2.4.0 in /usr/local/lib/python3.11/dist-packages (from apache-beam<3,>=2.53->apache-beam[gcp]<3,>=2.53; python_version >= \"3.11\"->tensorflow-data-validation==1.15.1) (2.4.0)\n",
            "Requirement already satisfied: zstandard<1,>=0.18.0 in /usr/local/lib/python3.11/dist-packages (from apache-beam<3,>=2.53->apache-beam[gcp]<3,>=2.53; python_version >= \"3.11\"->tensorflow-data-validation==1.15.1) (0.23.0)\n",
            "Requirement already satisfied: pyyaml<7.0.0,>=3.12 in /usr/local/lib/python3.11/dist-packages (from apache-beam<3,>=2.53->apache-beam[gcp]<3,>=2.53; python_version >= \"3.11\"->tensorflow-data-validation==1.15.1) (6.0.2)\n",
            "Collecting beartype<0.23.0,>=0.21.0 (from apache-beam<3,>=2.53->apache-beam[gcp]<3,>=2.53; python_version >= \"3.11\"->tensorflow-data-validation==1.15.1)\n",
            "  Downloading beartype-0.22.9-py3-none-any.whl.metadata (37 kB)\n",
            "Collecting pyarrow-hotfix<1 (from apache-beam<3,>=2.53->apache-beam[gcp]<3,>=2.53; python_version >= \"3.11\"->tensorflow-data-validation==1.15.1)\n",
            "  Downloading pyarrow_hotfix-0.7-py3-none-any.whl.metadata (3.6 kB)\n",
            "Requirement already satisfied: cachetools<7,>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from apache-beam[gcp]<3,>=2.53; python_version >= \"3.11\"->tensorflow-data-validation==1.15.1) (5.5.2)\n",
            "Requirement already satisfied: google-api-core<3,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from apache-beam[gcp]<3,>=2.53; python_version >= \"3.11\"->tensorflow-data-validation==1.15.1) (2.25.1)\n",
            "Collecting google-apitools<0.5.32,>=0.5.31 (from apache-beam[gcp]<3,>=2.53; python_version >= \"3.11\"->tensorflow-data-validation==1.15.1)\n",
            "  Downloading google-apitools-0.5.31.tar.gz (173 kB)\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: google-auth<3,>=1.18.0 in /usr/local/lib/python3.11/dist-packages (from apache-beam[gcp]<3,>=2.53; python_version >= \"3.11\"->tensorflow-data-validation==1.15.1) (2.38.0)\n",
            "Requirement already satisfied: google-auth-httplib2<0.3.0,>=0.1.0 in /usr/local/lib/python3.11/dist-packages (from apache-beam[gcp]<3,>=2.53; python_version >= \"3.11\"->tensorflow-data-validation==1.15.1) (0.2.0)\n",
            "Requirement already satisfied: google-cloud-datastore<3,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from apache-beam[gcp]<3,>=2.53; python_version >= \"3.11\"->tensorflow-data-validation==1.15.1) (2.21.0)\n",
            "Collecting google-cloud-pubsub<3,>=2.1.0 (from apache-beam[gcp]<3,>=2.53; python_version >= \"3.11\"->tensorflow-data-validation==1.15.1)\n",
            "  Downloading google_cloud_pubsub-2.34.0-py3-none-any.whl.metadata (10 kB)\n",
            "Collecting google-cloud-pubsublite<2,>=1.2.0 (from apache-beam[gcp]<3,>=2.53; python_version >= \"3.11\"->tensorflow-data-validation==1.15.1)\n",
            "  Downloading google_cloud_pubsublite-1.13.0-py3-none-any.whl.metadata (6.2 kB)\n",
            "Requirement already satisfied: google-cloud-storage<3,>=2.18.2 in /usr/local/lib/python3.11/dist-packages (from apache-beam[gcp]<3,>=2.53; python_version >= \"3.11\"->tensorflow-data-validation==1.15.1) (2.19.0)\n",
            "Requirement already satisfied: google-cloud-bigquery<4,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from apache-beam[gcp]<3,>=2.53; python_version >= \"3.11\"->tensorflow-data-validation==1.15.1) (3.34.0)\n",
            "Requirement already satisfied: google-cloud-bigquery-storage<3,>=2.6.3 in /usr/local/lib/python3.11/dist-packages (from apache-beam[gcp]<3,>=2.53; python_version >= \"3.11\"->tensorflow-data-validation==1.15.1) (2.32.0)\n",
            "Requirement already satisfied: google-cloud-core<3,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from apache-beam[gcp]<3,>=2.53; python_version >= \"3.11\"->tensorflow-data-validation==1.15.1) (2.4.3)\n",
            "Collecting google-cloud-bigtable<3,>=2.19.0 (from apache-beam[gcp]<3,>=2.53; python_version >= \"3.11\"->tensorflow-data-validation==1.15.1)\n",
            "  Downloading google_cloud_bigtable-2.35.0-py3-none-any.whl.metadata (5.8 kB)\n",
            "Requirement already satisfied: google-cloud-spanner<4,>=3.0.0 in /usr/local/lib/python3.11/dist-packages (from apache-beam[gcp]<3,>=2.53; python_version >= \"3.11\"->tensorflow-data-validation==1.15.1) (3.55.0)\n",
            "Collecting google-cloud-dlp<4,>=3.0.0 (from apache-beam[gcp]<3,>=2.53; python_version >= \"3.11\"->tensorflow-data-validation==1.15.1)\n",
            "  Downloading google_cloud_dlp-3.34.0-py3-none-any.whl.metadata (9.9 kB)\n",
            "Collecting google-cloud-kms<4,>=3.0.0 (from apache-beam[gcp]<3,>=2.53; python_version >= \"3.11\"->tensorflow-data-validation==1.15.1)\n",
            "  Downloading google_cloud_kms-3.10.0-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: google-cloud-language<3,>=2.0 in /usr/local/lib/python3.11/dist-packages (from apache-beam[gcp]<3,>=2.53; python_version >= \"3.11\"->tensorflow-data-validation==1.15.1) (2.17.2)\n",
            "Collecting google-cloud-secret-manager<3,>=2.0 (from apache-beam[gcp]<3,>=2.53; python_version >= \"3.11\"->tensorflow-data-validation==1.15.1)\n",
            "  Downloading google_cloud_secret_manager-2.26.0-py3-none-any.whl.metadata (9.8 kB)\n",
            "Collecting google-cloud-videointelligence<3,>=2.0 (from apache-beam[gcp]<3,>=2.53; python_version >= \"3.11\"->tensorflow-data-validation==1.15.1)\n",
            "  Downloading google_cloud_videointelligence-2.18.0-py3-none-any.whl.metadata (10 kB)\n",
            "Collecting google-cloud-vision<4,>=2 (from apache-beam[gcp]<3,>=2.53; python_version >= \"3.11\"->tensorflow-data-validation==1.15.1)\n",
            "  Downloading google_cloud_vision-3.12.0-py3-none-any.whl.metadata (9.8 kB)\n",
            "Collecting google-cloud-recommendations-ai<0.11.0,>=0.1.0 (from apache-beam[gcp]<3,>=2.53; python_version >= \"3.11\"->tensorflow-data-validation==1.15.1)\n",
            "  Downloading google_cloud_recommendations_ai-0.10.18-py3-none-any.whl.metadata (9.7 kB)\n",
            "Requirement already satisfied: google-cloud-aiplatform<2.0,>=1.26.0 in /usr/local/lib/python3.11/dist-packages (from apache-beam[gcp]<3,>=2.53; python_version >= \"3.11\"->tensorflow-data-validation==1.15.1) (1.103.0)\n",
            "Collecting cloud-sql-python-connector<2.0.0,>=1.18.2 (from apache-beam[gcp]<3,>=2.53; python_version >= \"3.11\"->tensorflow-data-validation==1.15.1)\n",
            "  Downloading cloud_sql_python_connector-1.20.0-py3-none-any.whl.metadata (31 kB)\n",
            "Collecting python-tds>=1.16.1 (from apache-beam[gcp]<3,>=2.53; python_version >= \"3.11\"->tensorflow-data-validation==1.15.1)\n",
            "  Downloading python_tds-1.17.1-py3-none-any.whl.metadata (804 bytes)\n",
            "Collecting pg8000>=1.31.5 (from apache-beam[gcp]<3,>=2.53; python_version >= \"3.11\"->tensorflow-data-validation==1.15.1)\n",
            "  Downloading pg8000-1.31.5-py3-none-any.whl.metadata (88 kB)\n",
            "Collecting PyMySQL>=1.1.0 (from apache-beam[gcp]<3,>=2.53; python_version >= \"3.11\"->tensorflow-data-validation==1.15.1)\n",
            "  Downloading pymysql-1.1.2-py3-none-any.whl.metadata (4.3 kB)\n",
            "Requirement already satisfied: keyrings.google-artifactregistry-auth in /usr/local/lib/python3.11/dist-packages (from apache-beam[gcp]<3,>=2.53; python_version >= \"3.11\"->tensorflow-data-validation==1.15.1) (1.1.2)\n",
            "Requirement already satisfied: orjson<4,>=3.9.7 in /usr/local/lib/python3.11/dist-packages (from apache-beam[gcp]<3,>=2.53; python_version >= \"3.11\"->tensorflow-data-validation==1.15.1) (3.10.18)\n",
            "Requirement already satisfied: regex>=2020.6.8 in /usr/local/lib/python3.11/dist-packages (from apache-beam[gcp]<3,>=2.53; python_version >= \"3.11\"->tensorflow-data-validation==1.15.1) (2024.11.6)\n",
            "Requirement already satisfied: aiofiles in /usr/local/lib/python3.11/dist-packages (from cloud-sql-python-connector<2.0.0,>=1.18.2->apache-beam[gcp]<3,>=2.53; python_version >= \"3.11\"->tensorflow-data-validation==1.15.1) (24.1.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from cloud-sql-python-connector<2.0.0,>=1.18.2->apache-beam[gcp]<3,>=2.53; python_version >= \"3.11\"->tensorflow-data-validation==1.15.1) (3.11.15)\n",
            "Collecting dnspython>=2.0.0 (from cloud-sql-python-connector<2.0.0,>=1.18.2->apache-beam[gcp]<3,>=2.53; python_version >= \"3.11\"->tensorflow-data-validation==1.15.1)\n",
            "  Downloading dnspython-2.8.0-py3-none-any.whl.metadata (5.7 kB)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.11/dist-packages (from cryptography<48.0.0,>=39.0.0->apache-beam<3,>=2.53->apache-beam[gcp]<3,>=2.53; python_version >= \"3.11\"->tensorflow-data-validation==1.15.1) (1.17.1)\n",
            "Requirement already satisfied: betterproto<3.0.0,>=2.0.0b3 in /usr/local/lib/python3.11/dist-packages (from envoy-data-plane<0.3.0->apache-beam<3,>=2.53->apache-beam[gcp]<3,>=2.53; python_version >= \"3.11\"->tensorflow-data-validation==1.15.1) (2.0.0b6)\n",
            "Requirement already satisfied: grpclib<0.5.0,>=0.4.1 in /usr/local/lib/python3.11/dist-packages (from betterproto<3.0.0,>=2.0.0b3->envoy-data-plane<0.3.0->apache-beam<3,>=2.53->apache-beam[gcp]<3,>=2.53; python_version >= \"3.11\"->tensorflow-data-validation==1.15.1) (0.4.8)\n",
            "Requirement already satisfied: oauth2client>=1.4.12 in /usr/local/lib/python3.11/dist-packages (from google-apitools<0.5.32,>=0.5.31->apache-beam[gcp]<3,>=2.53; python_version >= \"3.11\"->tensorflow-data-validation==1.15.1) (4.1.3)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth<3,>=1.18.0->apache-beam[gcp]<3,>=2.53; python_version >= \"3.11\"->tensorflow-data-validation==1.15.1) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth<3,>=1.18.0->apache-beam[gcp]<3,>=2.53; python_version >= \"3.11\"->tensorflow-data-validation==1.15.1) (4.9.1)\n",
            "Requirement already satisfied: google-cloud-resource-manager<3.0.0,>=1.3.3 in /usr/local/lib/python3.11/dist-packages (from google-cloud-aiplatform<2.0,>=1.26.0->apache-beam[gcp]<3,>=2.53; python_version >= \"3.11\"->tensorflow-data-validation==1.15.1) (1.14.2)\n",
            "Requirement already satisfied: shapely<3.0.0 in /usr/local/lib/python3.11/dist-packages (from google-cloud-aiplatform<2.0,>=1.26.0->apache-beam[gcp]<3,>=2.53; python_version >= \"3.11\"->tensorflow-data-validation==1.15.1) (2.1.1)\n",
            "Requirement already satisfied: google-genai<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from google-cloud-aiplatform<2.0,>=1.26.0->apache-beam[gcp]<3,>=2.53; python_version >= \"3.11\"->tensorflow-data-validation==1.15.1) (1.25.0)\n",
            "Requirement already satisfied: pydantic<3 in /usr/local/lib/python3.11/dist-packages (from google-cloud-aiplatform<2.0,>=1.26.0->apache-beam[gcp]<3,>=2.53; python_version >= \"3.11\"->tensorflow-data-validation==1.15.1) (2.11.7)\n",
            "Requirement already satisfied: docstring_parser<1 in /usr/local/lib/python3.11/dist-packages (from google-cloud-aiplatform<2.0,>=1.26.0->apache-beam[gcp]<3,>=2.53; python_version >= \"3.11\"->tensorflow-data-validation==1.15.1) (0.16)\n",
            "Requirement already satisfied: grpcio-status<2.0.0,>=1.33.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0,>=1.34.1->google-cloud-aiplatform<2.0,>=1.26.0->apache-beam[gcp]<3,>=2.53; python_version >= \"3.11\"->tensorflow-data-validation==1.15.1) (1.71.2)\n",
            "Requirement already satisfied: google-resumable-media<3.0.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from google-cloud-bigquery<4,>=2.0.0->apache-beam[gcp]<3,>=2.53; python_version >= \"3.11\"->tensorflow-data-validation==1.15.1) (2.7.2)\n",
            "Requirement already satisfied: grpc-google-iam-v1<1.0.0,>=0.12.4 in /usr/local/lib/python3.11/dist-packages (from google-cloud-bigtable<3,>=2.19.0->apache-beam[gcp]<3,>=2.53; python_version >= \"3.11\"->tensorflow-data-validation==1.15.1) (0.14.2)\n",
            "Requirement already satisfied: google-crc32c<2.0.0dev,>=1.5.0 in /usr/local/lib/python3.11/dist-packages (from google-cloud-bigtable<3,>=2.19.0->apache-beam[gcp]<3,>=2.53; python_version >= \"3.11\"->tensorflow-data-validation==1.15.1) (1.7.1)\n",
            "Collecting opentelemetry-api>=1.27.0 (from google-cloud-pubsub<3,>=2.1.0->apache-beam[gcp]<3,>=2.53; python_version >= \"3.11\"->tensorflow-data-validation==1.15.1)\n",
            "  Downloading opentelemetry_api-1.39.1-py3-none-any.whl.metadata (1.5 kB)\n",
            "Collecting opentelemetry-sdk>=1.27.0 (from google-cloud-pubsub<3,>=2.1.0->apache-beam[gcp]<3,>=2.53; python_version >= \"3.11\"->tensorflow-data-validation==1.15.1)\n",
            "  Downloading opentelemetry_sdk-1.39.1-py3-none-any.whl.metadata (1.5 kB)\n",
            "Collecting overrides<8.0.0,>=6.0.1 (from google-cloud-pubsublite<2,>=1.2.0->apache-beam[gcp]<3,>=2.53; python_version >= \"3.11\"->tensorflow-data-validation==1.15.1)\n",
            "  Downloading overrides-7.7.0-py3-none-any.whl.metadata (5.8 kB)\n",
            "Requirement already satisfied: sqlparse>=0.4.4 in /usr/local/lib/python3.11/dist-packages (from google-cloud-spanner<4,>=3.0.0->apache-beam[gcp]<3,>=2.53; python_version >= \"3.11\"->tensorflow-data-validation==1.15.1) (0.5.3)\n",
            "Requirement already satisfied: grpc-interceptor>=0.15.4 in /usr/local/lib/python3.11/dist-packages (from google-cloud-spanner<4,>=3.0.0->apache-beam[gcp]<3,>=2.53; python_version >= \"3.11\"->tensorflow-data-validation==1.15.1) (0.15.4)\n",
            "Requirement already satisfied: anyio<5.0.0,>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from google-genai<2.0.0,>=1.0.0->google-cloud-aiplatform<2.0,>=1.26.0->apache-beam[gcp]<3,>=2.53; python_version >= \"3.11\"->tensorflow-data-validation==1.15.1) (4.9.0)\n",
            "Requirement already satisfied: httpx<1.0.0,>=0.28.1 in /usr/local/lib/python3.11/dist-packages (from google-genai<2.0.0,>=1.0.0->google-cloud-aiplatform<2.0,>=1.26.0->apache-beam[gcp]<3,>=2.53; python_version >= \"3.11\"->tensorflow-data-validation==1.15.1) (0.28.1)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.2.3 in /usr/local/lib/python3.11/dist-packages (from google-genai<2.0.0,>=1.0.0->google-cloud-aiplatform<2.0,>=1.26.0->apache-beam[gcp]<3,>=2.53; python_version >= \"3.11\"->tensorflow-data-validation==1.15.1) (8.5.0)\n",
            "Requirement already satisfied: websockets<15.1.0,>=13.0.0 in /usr/local/lib/python3.11/dist-packages (from google-genai<2.0.0,>=1.0.0->google-cloud-aiplatform<2.0,>=1.26.0->apache-beam[gcp]<3,>=2.53; python_version >= \"3.11\"->tensorflow-data-validation==1.15.1) (15.0.1)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5.0.0,>=4.8.0->google-genai<2.0.0,>=1.0.0->google-cloud-aiplatform<2.0,>=1.26.0->apache-beam[gcp]<3,>=2.53; python_version >= \"3.11\"->tensorflow-data-validation==1.15.1) (3.10)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio<5.0.0,>=4.8.0->google-genai<2.0.0,>=1.0.0->google-cloud-aiplatform<2.0,>=1.26.0->apache-beam[gcp]<3,>=2.53; python_version >= \"3.11\"->tensorflow-data-validation==1.15.1) (1.3.1)\n",
            "INFO: pip is looking at multiple versions of grpcio-status to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting grpcio-status<2.0.0,>=1.33.2 (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0,>=1.34.1->google-cloud-aiplatform<2.0,>=1.26.0->apache-beam[gcp]<3,>=2.53; python_version >= \"3.11\"->tensorflow-data-validation==1.15.1)\n",
            "  Downloading grpcio_status-1.76.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "  Downloading grpcio_status-1.75.1-py3-none-any.whl.metadata (1.1 kB)\n",
            "  Downloading grpcio_status-1.75.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "  Downloading grpcio_status-1.74.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "  Downloading grpcio_status-1.73.1-py3-none-any.whl.metadata (1.1 kB)\n",
            "  Downloading grpcio_status-1.73.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "  Downloading grpcio_status-1.72.2-py3-none-any.whl.metadata (1.1 kB)\n",
            "INFO: pip is still looking at multiple versions of grpcio-status to determine which version is compatible with other requirements. This could take a while.\n",
            "  Downloading grpcio_status-1.72.1-py3-none-any.whl.metadata (1.1 kB)\n",
            "  Downloading grpcio_status-1.71.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "  Downloading grpcio_status-1.70.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "  Downloading grpcio_status-1.69.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "  Downloading grpcio_status-1.68.1-py3-none-any.whl.metadata (1.1 kB)\n",
            "INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n",
            "  Downloading grpcio_status-1.68.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "  Downloading grpcio_status-1.67.1-py3-none-any.whl.metadata (1.1 kB)\n",
            "  Downloading grpcio_status-1.67.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "  Downloading grpcio_status-1.66.2-py3-none-any.whl.metadata (1.1 kB)\n",
            "  Downloading grpcio_status-1.66.1-py3-none-any.whl.metadata (1.1 kB)\n",
            "  Downloading grpcio_status-1.66.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "  Downloading grpcio_status-1.65.5-py3-none-any.whl.metadata (1.1 kB)\n",
            "  Downloading grpcio_status-1.65.4-py3-none-any.whl.metadata (1.1 kB)\n",
            "  Downloading grpcio_status-1.65.2-py3-none-any.whl.metadata (1.1 kB)\n",
            "  Downloading grpcio_status-1.65.1-py3-none-any.whl.metadata (1.1 kB)\n",
            "  Downloading grpcio_status-1.64.3-py3-none-any.whl.metadata (1.1 kB)\n",
            "  Downloading grpcio_status-1.64.1-py3-none-any.whl.metadata (1.1 kB)\n",
            "  Downloading grpcio_status-1.64.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "  Downloading grpcio_status-1.63.2-py3-none-any.whl.metadata (1.1 kB)\n",
            "  Downloading grpcio_status-1.63.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "  Downloading grpcio_status-1.62.3-py3-none-any.whl.metadata (1.3 kB)\n",
            "Requirement already satisfied: h2<5,>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from grpclib<0.5.0,>=0.4.1->betterproto<3.0.0,>=2.0.0b3->envoy-data-plane<0.3.0->apache-beam<3,>=2.53->apache-beam[gcp]<3,>=2.53; python_version >= \"3.11\"->tensorflow-data-validation==1.15.1) (4.2.0)\n",
            "Requirement already satisfied: multidict in /usr/local/lib/python3.11/dist-packages (from grpclib<0.5.0,>=0.4.1->betterproto<3.0.0,>=2.0.0b3->envoy-data-plane<0.3.0->apache-beam<3,>=2.53->apache-beam[gcp]<3,>=2.53; python_version >= \"3.11\"->tensorflow-data-validation==1.15.1) (6.6.3)\n",
            "Requirement already satisfied: hyperframe<7,>=6.1 in /usr/local/lib/python3.11/dist-packages (from h2<5,>=3.1.0->grpclib<0.5.0,>=0.4.1->betterproto<3.0.0,>=2.0.0b3->envoy-data-plane<0.3.0->apache-beam<3,>=2.53->apache-beam[gcp]<3,>=2.53; python_version >= \"3.11\"->tensorflow-data-validation==1.15.1) (6.1.0)\n",
            "Requirement already satisfied: hpack<5,>=4.1 in /usr/local/lib/python3.11/dist-packages (from h2<5,>=3.1.0->grpclib<0.5.0,>=0.4.1->betterproto<3.0.0,>=2.0.0b3->envoy-data-plane<0.3.0->apache-beam<3,>=2.53->apache-beam[gcp]<3,>=2.53; python_version >= \"3.11\"->tensorflow-data-validation==1.15.1) (4.1.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in /usr/local/lib/python3.11/dist-packages (from httplib2<0.23.0,>=0.8->apache-beam<3,>=2.53->apache-beam[gcp]<3,>=2.53; python_version >= \"3.11\"->tensorflow-data-validation==1.15.1) (3.2.3)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1.0.0,>=0.28.1->google-genai<2.0.0,>=1.0.0->google-cloud-aiplatform<2.0,>=1.26.0->apache-beam[gcp]<3,>=2.53; python_version >= \"3.11\"->tensorflow-data-validation==1.15.1) (2025.7.14)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1.0.0,>=0.28.1->google-genai<2.0.0,>=1.0.0->google-cloud-aiplatform<2.0,>=1.26.0->apache-beam[gcp]<3,>=2.53; python_version >= \"3.11\"->tensorflow-data-validation==1.15.1) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1.0.0,>=0.28.1->google-genai<2.0.0,>=1.0.0->google-cloud-aiplatform<2.0,>=1.26.0->apache-beam[gcp]<3,>=2.53; python_version >= \"3.11\"->tensorflow-data-validation==1.15.1) (0.16.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3->google-cloud-aiplatform<2.0,>=1.26.0->apache-beam[gcp]<3,>=2.53; python_version >= \"3.11\"->tensorflow-data-validation==1.15.1) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3->google-cloud-aiplatform<2.0,>=1.26.0->apache-beam[gcp]<3,>=2.53; python_version >= \"3.11\"->tensorflow-data-validation==1.15.1) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3->google-cloud-aiplatform<2.0,>=1.26.0->apache-beam[gcp]<3,>=2.53; python_version >= \"3.11\"->tensorflow-data-validation==1.15.1) (0.4.1)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.32.4->apache-beam<3,>=2.53->apache-beam[gcp]<3,>=2.53; python_version >= \"3.11\"->tensorflow-data-validation==1.15.1) (3.4.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.32.4->apache-beam<3,>=2.53->apache-beam[gcp]<3,>=2.53; python_version >= \"3.11\"->tensorflow-data-validation==1.15.1) (2.4.0)\n",
            "Requirement already satisfied: pyasn1>=0.1.3 in /usr/local/lib/python3.11/dist-packages (from rsa<5,>=3.1.4->google-auth<3,>=1.18.0->apache-beam[gcp]<3,>=2.53; python_version >= \"3.11\"->tensorflow-data-validation==1.15.1) (0.6.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.16,>=2.15->tensorflow==2.15.1) (1.2.2)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.16,>=2.15->tensorflow==2.15.1) (3.8.2)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.16,>=2.15->tensorflow==2.15.1) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.16,>=2.15->tensorflow==2.15.1) (3.1.3)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow==2.15.1) (2.0.0)\n",
            "Collecting google-api-python-client<2,>=1.7.11 (from tfx-bsl<1.16,>=1.15.1->tensorflow-data-validation==1.15.1)\n",
            "  Downloading google_api_python_client-1.12.11-py2.py3-none-any.whl.metadata (4.2 kB)\n",
            "Collecting tensorflow-serving-api<3,>=2.13.0 (from tfx-bsl<1.16,>=1.15.1->tensorflow-data-validation==1.15.1)\n",
            "  Downloading tensorflow_serving_api-2.19.1-py2.py3-none-any.whl.metadata (1.8 kB)\n",
            "Collecting uritemplate<4dev,>=3.0.0 (from google-api-python-client<2,>=1.7.11->tfx-bsl<1.16,>=1.15.1->tensorflow-data-validation==1.15.1)\n",
            "  Downloading uritemplate-3.0.1-py2.py3-none-any.whl.metadata (4.6 kB)\n",
            "INFO: pip is looking at multiple versions of tensorflow-serving-api to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting tensorflow-serving-api<3,>=2.13.0 (from tfx-bsl<1.16,>=1.15.1->tensorflow-data-validation==1.15.1)\n",
            "  Downloading tensorflow_serving_api-2.19.0-py2.py3-none-any.whl.metadata (1.8 kB)\n",
            "  Downloading tensorflow_serving_api-2.18.1-py2.py3-none-any.whl.metadata (1.8 kB)\n",
            "  Downloading tensorflow_serving_api-2.18.0-py2.py3-none-any.whl.metadata (1.8 kB)\n",
            "  Downloading tensorflow_serving_api-2.17.1-py2.py3-none-any.whl.metadata (1.8 kB)\n",
            "  Downloading tensorflow_serving_api-2.17.0-py2.py3-none-any.whl.metadata (1.8 kB)\n",
            "  Downloading tensorflow_serving_api-2.16.1-py2.py3-none-any.whl.metadata (1.8 kB)\n",
            "  Downloading tensorflow_serving_api-2.15.1-py2.py3-none-any.whl.metadata (1.8 kB)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from astunparse>=1.6.0->tensorflow==2.15.1) (0.45.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.12->cryptography<48.0.0,>=39.0.0->apache-beam<3,>=2.53->apache-beam[gcp]<3,>=2.53; python_version >= \"3.11\"->tensorflow-data-validation==1.15.1) (2.22)\n",
            "Requirement already satisfied: importlib-metadata<8.8.0,>=6.0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-api>=1.27.0->google-cloud-pubsub<3,>=2.1.0->apache-beam[gcp]<3,>=2.53; python_version >= \"3.11\"->tensorflow-data-validation==1.15.1) (8.7.0)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.11/dist-packages (from importlib-metadata<8.8.0,>=6.0->opentelemetry-api>=1.27.0->google-cloud-pubsub<3,>=2.1.0->apache-beam[gcp]<3,>=2.53; python_version >= \"3.11\"->tensorflow-data-validation==1.15.1) (3.23.0)\n",
            "Collecting opentelemetry-semantic-conventions==0.60b1 (from opentelemetry-sdk>=1.27.0->google-cloud-pubsub<3,>=2.1.0->apache-beam[gcp]<3,>=2.53; python_version >= \"3.11\"->tensorflow-data-validation==1.15.1)\n",
            "  Downloading opentelemetry_semantic_conventions-0.60b1-py3-none-any.whl.metadata (2.4 kB)\n",
            "Collecting scramp>=1.4.5 (from pg8000>=1.31.5->apache-beam[gcp]<3,>=2.53; python_version >= \"3.11\"->tensorflow-data-validation==1.15.1)\n",
            "  Downloading scramp-1.4.8-py3-none-any.whl.metadata (18 kB)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.11/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow==2.15.1) (3.3.1)\n",
            "Collecting asn1crypto>=1.5.1 (from scramp>=1.4.5->pg8000>=1.31.5->apache-beam[gcp]<3,>=2.53; python_version >= \"3.11\"->tensorflow-data-validation==1.15.1)\n",
            "  Downloading asn1crypto-1.5.1-py2.py3-none-any.whl.metadata (13 kB)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tensorboard<2.16,>=2.15->tensorflow==2.15.1) (3.0.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->cloud-sql-python-connector<2.0.0,>=1.18.2->apache-beam[gcp]<3,>=2.53; python_version >= \"3.11\"->tensorflow-data-validation==1.15.1) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->cloud-sql-python-connector<2.0.0,>=1.18.2->apache-beam[gcp]<3,>=2.53; python_version >= \"3.11\"->tensorflow-data-validation==1.15.1) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->cloud-sql-python-connector<2.0.0,>=1.18.2->apache-beam[gcp]<3,>=2.53; python_version >= \"3.11\"->tensorflow-data-validation==1.15.1) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->cloud-sql-python-connector<2.0.0,>=1.18.2->apache-beam[gcp]<3,>=2.53; python_version >= \"3.11\"->tensorflow-data-validation==1.15.1) (1.7.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->cloud-sql-python-connector<2.0.0,>=1.18.2->apache-beam[gcp]<3,>=2.53; python_version >= \"3.11\"->tensorflow-data-validation==1.15.1) (0.3.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->cloud-sql-python-connector<2.0.0,>=1.18.2->apache-beam[gcp]<3,>=2.53; python_version >= \"3.11\"->tensorflow-data-validation==1.15.1) (1.20.1)\n",
            "Requirement already satisfied: keyring in /usr/local/lib/python3.11/dist-packages (from keyrings.google-artifactregistry-auth->apache-beam[gcp]<3,>=2.53; python_version >= \"3.11\"->tensorflow-data-validation==1.15.1) (25.6.0)\n",
            "Requirement already satisfied: pluggy in /usr/local/lib/python3.11/dist-packages (from keyrings.google-artifactregistry-auth->apache-beam[gcp]<3,>=2.53; python_version >= \"3.11\"->tensorflow-data-validation==1.15.1) (1.6.0)\n",
            "Requirement already satisfied: SecretStorage>=3.2 in /usr/local/lib/python3.11/dist-packages (from keyring->keyrings.google-artifactregistry-auth->apache-beam[gcp]<3,>=2.53; python_version >= \"3.11\"->tensorflow-data-validation==1.15.1) (3.3.3)\n",
            "Requirement already satisfied: jeepney>=0.4.2 in /usr/local/lib/python3.11/dist-packages (from keyring->keyrings.google-artifactregistry-auth->apache-beam[gcp]<3,>=2.53; python_version >= \"3.11\"->tensorflow-data-validation==1.15.1) (0.9.0)\n",
            "Requirement already satisfied: jaraco.classes in /usr/local/lib/python3.11/dist-packages (from keyring->keyrings.google-artifactregistry-auth->apache-beam[gcp]<3,>=2.53; python_version >= \"3.11\"->tensorflow-data-validation==1.15.1) (3.4.0)\n",
            "Requirement already satisfied: jaraco.functools in /usr/local/lib/python3.11/dist-packages (from keyring->keyrings.google-artifactregistry-auth->apache-beam[gcp]<3,>=2.53; python_version >= \"3.11\"->tensorflow-data-validation==1.15.1) (4.2.1)\n",
            "Requirement already satisfied: jaraco.context in /usr/local/lib/python3.11/dist-packages (from keyring->keyrings.google-artifactregistry-auth->apache-beam[gcp]<3,>=2.53; python_version >= \"3.11\"->tensorflow-data-validation==1.15.1) (6.0.1)\n",
            "Requirement already satisfied: more-itertools in /usr/local/lib/python3.11/dist-packages (from jaraco.classes->keyring->keyrings.google-artifactregistry-auth->apache-beam[gcp]<3,>=2.53; python_version >= \"3.11\"->tensorflow-data-validation==1.15.1) (10.7.0)\n",
            "Requirement already satisfied: backports.tarfile in /usr/local/lib/python3.11/dist-packages (from jaraco.context->keyring->keyrings.google-artifactregistry-auth->apache-beam[gcp]<3,>=2.53; python_version >= \"3.11\"->tensorflow-data-validation==1.15.1) (1.2.0)\n",
            "Downloading tensorflow-2.15.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (475.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m475.3/475.3 MB\u001b[0m \u001b[31m55.9 MB/s\u001b[0m  \u001b[33m0:00:05\u001b[0m\n",
            "\u001b[?25hDownloading tensorflow_metadata-1.15.0-py3-none-any.whl (28 kB)\n",
            "Downloading tensorflow_data_validation-1.15.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (19.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.0/19.0 MB\u001b[0m \u001b[31m82.3 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading apache_beam-2.71.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.4/17.4 MB\u001b[0m \u001b[31m142.2 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading beartype-0.22.9-py3-none-any.whl (1.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m75.2 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading cloud_sql_python_connector-1.20.0-py3-none-any.whl (50 kB)\n",
            "Downloading envoy_data_plane-0.2.6-py3-none-any.whl (816 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m816.4/816.4 kB\u001b[0m \u001b[31m38.7 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading fastavro-1.12.1-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (3.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m105.8 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading fasteners-0.20-py3-none-any.whl (18 kB)\n",
            "Downloading google_cloud_bigtable-2.35.0-py3-none-any.whl (540 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m540.3/540.3 kB\u001b[0m \u001b[31m24.3 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading google_cloud_dlp-3.34.0-py3-none-any.whl (220 kB)\n",
            "Downloading google_cloud_kms-3.10.0-py3-none-any.whl (339 kB)\n",
            "Downloading google_cloud_pubsub-2.34.0-py3-none-any.whl (320 kB)\n",
            "Downloading google_cloud_pubsublite-1.13.0-py3-none-any.whl (324 kB)\n",
            "Downloading google_cloud_recommendations_ai-0.10.18-py3-none-any.whl (212 kB)\n",
            "Downloading google_cloud_secret_manager-2.26.0-py3-none-any.whl (223 kB)\n",
            "Downloading google_cloud_videointelligence-2.18.0-py3-none-any.whl (285 kB)\n",
            "Downloading google_cloud_vision-3.12.0-py3-none-any.whl (538 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m538.2/538.2 kB\u001b[0m \u001b[31m18.7 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading grpcio-1.65.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.7/5.7 MB\u001b[0m \u001b[31m130.9 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading grpcio_status-1.62.3-py3-none-any.whl (14 kB)\n",
            "Downloading jsonpickle-3.4.2-py3-none-any.whl (46 kB)\n",
            "Downloading keras-2.15.0-py3-none-any.whl (1.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m59.3 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ml_dtypes-0.3.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m99.0 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.3/18.3 MB\u001b[0m \u001b[31m71.3 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading objsize-0.7.1-py3-none-any.whl (11 kB)\n",
            "Downloading overrides-7.7.0-py3-none-any.whl (17 kB)\n",
            "Downloading pandas-1.5.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.0/12.0 MB\u001b[0m \u001b[31m116.6 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading protobuf-4.25.8-cp37-abi3-manylinux2014_x86_64.whl (294 kB)\n",
            "Downloading pyarrow-10.0.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (35.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m35.8/35.8 MB\u001b[0m \u001b[31m67.6 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyarrow_hotfix-0.7-py3-none-any.whl (7.9 kB)\n",
            "Downloading pymongo-4.16.0-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (1.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m78.7 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dnspython-2.8.0-py3-none-any.whl (331 kB)\n",
            "Downloading requests-2.32.5-py3-none-any.whl (64 kB)\n",
            "Downloading tensorboard-2.15.2-py3-none-any.whl (5.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m116.0 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tensorflow_estimator-2.15.0-py2.py3-none-any.whl (441 kB)\n",
            "Downloading tfx_bsl-1.15.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (22.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m22.5/22.5 MB\u001b[0m \u001b[31m50.5 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading google_api_python_client-1.12.11-py2.py3-none-any.whl (62 kB)\n",
            "Downloading tensorflow_serving_api-2.15.1-py2.py3-none-any.whl (26 kB)\n",
            "Downloading uritemplate-3.0.1-py2.py3-none-any.whl (15 kB)\n",
            "Downloading wrapt-1.14.2-cp311-cp311-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl (77 kB)\n",
            "Downloading opentelemetry_api-1.39.1-py3-none-any.whl (66 kB)\n",
            "Downloading opentelemetry_sdk-1.39.1-py3-none-any.whl (132 kB)\n",
            "Downloading opentelemetry_semantic_conventions-0.60b1-py3-none-any.whl (219 kB)\n",
            "Downloading pg8000-1.31.5-py3-none-any.whl (57 kB)\n",
            "Downloading pymysql-1.1.2-py3-none-any.whl (45 kB)\n",
            "Downloading python_tds-1.17.1-py3-none-any.whl (86 kB)\n",
            "Downloading scramp-1.4.8-py3-none-any.whl (13 kB)\n",
            "Downloading asn1crypto-1.5.1-py2.py3-none-any.whl (105 kB)\n",
            "Building wheels for collected packages: google-apitools, pyfarmhash\n",
            "  Building wheel for google-apitools (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for google-apitools: filename=google_apitools-0.5.31-py3-none-any.whl size=131077 sha256=4fee6ac2831a43ae5163e82284fdc4588cb55621864ddb53bfd33db18f72e153\n",
            "  Stored in directory: /root/.cache/pip/wheels/b4/7b/c5/b3dc55a0d70c63727a2fd1332b3cc14193d6d12219aa1372c4\n",
            "  Building wheel for pyfarmhash (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyfarmhash: filename=pyfarmhash-0.3.2-cp311-cp311-linux_x86_64.whl size=88745 sha256=dafd2d43bfecb4a6f6eb1e218bbdf59cfa4d2d3e6112d26c2a93fd2ba25407c5\n",
            "  Stored in directory: /root/.cache/pip/wheels/06/9a/f4/53839ebeb753b56ac36f76456e54854347c7b6e634731fbc03\n",
            "Successfully built google-apitools pyfarmhash\n",
            "Installing collected packages: python-tds, pyfarmhash, asn1crypto, wrapt, uritemplate, tensorflow-estimator, scramp, requests, PyMySQL, pyarrow-hotfix, protobuf, overrides, objsize, numpy, keras, jsonpickle, grpcio, fasteners, fastavro, dnspython, beartype, pymongo, pyarrow, pg8000, pandas, opentelemetry-api, ml-dtypes, tensorflow-metadata, opentelemetry-semantic-conventions, grpcio-status, google-apitools, cloud-sql-python-connector, tensorboard, opentelemetry-sdk, google-api-python-client, envoy-data-plane, tensorflow, google-cloud-vision, google-cloud-videointelligence, google-cloud-secret-manager, google-cloud-recommendations-ai, google-cloud-pubsub, google-cloud-kms, google-cloud-dlp, google-cloud-bigtable, apache-beam, tensorflow-serving-api, google-cloud-pubsublite, tfx-bsl, tensorflow-data-validation\n",
            "\u001b[2K  Attempting uninstall: wrapt\n",
            "\u001b[2K    Found existing installation: wrapt 1.17.2\n",
            "\u001b[2K    Uninstalling wrapt-1.17.2:\n",
            "\u001b[2K      Successfully uninstalled wrapt-1.17.2\n",
            "\u001b[2K  Attempting uninstall: uritemplate\n",
            "\u001b[2K    Found existing installation: uritemplate 4.2.0\n",
            "\u001b[2K    Uninstalling uritemplate-4.2.0:\n",
            "\u001b[2K      Successfully uninstalled uritemplate-4.2.0\n",
            "\u001b[2K  Attempting uninstall: requests\n",
            "\u001b[2K    Found existing installation: requests 2.32.3\n",
            "\u001b[2K    Uninstalling requests-2.32.3:\n",
            "\u001b[2K      Successfully uninstalled requests-2.32.3\n",
            "\u001b[2K  Attempting uninstall: protobuf\n",
            "\u001b[2K    Found existing installation: protobuf 5.29.5\n",
            "\u001b[2K    Uninstalling protobuf-5.29.5:\n",
            "\u001b[2K      Successfully uninstalled protobuf-5.29.5\n",
            "\u001b[2K  Attempting uninstall: numpy\n",
            "\u001b[2K    Found existing installation: numpy 2.0.2\n",
            "\u001b[2K    Uninstalling numpy-2.0.2:\n",
            "\u001b[2K      Successfully uninstalled numpy-2.0.2\n",
            "\u001b[2K  Attempting uninstall: keras\n",
            "\u001b[2K    Found existing installation: keras 3.8.0\n",
            "\u001b[2K    Uninstalling keras-3.8.0:\n",
            "\u001b[2K      Successfully uninstalled keras-3.8.0\n",
            "\u001b[2K  Attempting uninstall: jsonpickle\n",
            "\u001b[2K    Found existing installation: jsonpickle 4.1.1\n",
            "\u001b[2K    Uninstalling jsonpickle-4.1.1:\n",
            "\u001b[2K      Successfully uninstalled jsonpickle-4.1.1\n",
            "\u001b[2K  Attempting uninstall: grpcio\n",
            "\u001b[2K    Found existing installation: grpcio 1.73.1\n",
            "\u001b[2K    Uninstalling grpcio-1.73.1:\n",
            "\u001b[2K      Successfully uninstalled grpcio-1.73.1\n",
            "\u001b[2K  Attempting uninstall: pyarrow\n",
            "\u001b[2K    Found existing installation: pyarrow 18.1.0\n",
            "\u001b[2K    Uninstalling pyarrow-18.1.0:\n",
            "\u001b[2K      Successfully uninstalled pyarrow-18.1.0\n",
            "\u001b[2K  Attempting uninstall: pandas\n",
            "\u001b[2K    Found existing installation: pandas 2.2.2\n",
            "\u001b[2K    Uninstalling pandas-2.2.2:\n",
            "\u001b[2K      Successfully uninstalled pandas-2.2.2\n",
            "\u001b[2K  Attempting uninstall: ml-dtypes\n",
            "\u001b[2K    Found existing installation: ml-dtypes 0.4.1\n",
            "\u001b[2K    Uninstalling ml-dtypes-0.4.1:\n",
            "\u001b[2K      Successfully uninstalled ml-dtypes-0.4.1\n",
            "\u001b[2K  Attempting uninstall: tensorflow-metadata\n",
            "\u001b[2K    Found existing installation: tensorflow-metadata 1.17.2\n",
            "\u001b[2K    Uninstalling tensorflow-metadata-1.17.2:\n",
            "\u001b[2K      Successfully uninstalled tensorflow-metadata-1.17.2\n",
            "\u001b[2K  Attempting uninstall: grpcio-status\n",
            "\u001b[2K    Found existing installation: grpcio-status 1.71.2\n",
            "\u001b[2K    Uninstalling grpcio-status-1.71.2:\n",
            "\u001b[2K      Successfully uninstalled grpcio-status-1.71.2\n",
            "\u001b[2K  Attempting uninstall: tensorboard\n",
            "\u001b[2K    Found existing installation: tensorboard 2.18.0\n",
            "\u001b[2K    Uninstalling tensorboard-2.18.0:\n",
            "\u001b[2K      Successfully uninstalled tensorboard-2.18.0\n",
            "\u001b[2K  Attempting uninstall: google-api-python-client\n",
            "\u001b[2K    Found existing installation: google-api-python-client 2.176.0\n",
            "\u001b[2K    Uninstalling google-api-python-client-2.176.0:\n",
            "\u001b[2K      Successfully uninstalled google-api-python-client-2.176.0\n",
            "\u001b[2K  Attempting uninstall: tensorflow\n",
            "\u001b[2K    Found existing installation: tensorflow 2.18.0\n",
            "\u001b[2K    Uninstalling tensorflow-2.18.0:\n",
            "\u001b[2K      Successfully uninstalled tensorflow-2.18.0\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50/50\u001b[0m [tensorflow-data-validation]\n",
            "\u001b[1A\u001b[2K\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires pandas==2.2.2, but you have pandas 1.5.3 which is incompatible.\n",
            "google-colab 1.0.0 requires requests==2.32.3, but you have requests 2.32.5 which is incompatible.\n",
            "bigframes 2.10.0 requires pyarrow>=15.0.2, but you have pyarrow 10.0.1 which is incompatible.\n",
            "cudf-cu12 25.2.1 requires pandas<2.2.4dev0,>=2.0, but you have pandas 1.5.3 which is incompatible.\n",
            "cudf-cu12 25.2.1 requires pyarrow<20.0.0a0,>=14.0.0; platform_machine == \"x86_64\", but you have pyarrow 10.0.1 which is incompatible.\n",
            "dask-cudf-cu12 25.2.2 requires pandas<2.2.4dev0,>=2.0, but you have pandas 1.5.3 which is incompatible.\n",
            "dask-expr 1.1.21 requires pandas>=2, but you have pandas 1.5.3 which is incompatible.\n",
            "dask-expr 1.1.21 requires pyarrow>=14.0.1, but you have pyarrow 10.0.1 which is incompatible.\n",
            "db-dtypes 1.4.3 requires pyarrow>=13.0.0, but you have pyarrow 10.0.1 which is incompatible.\n",
            "jax 0.5.2 requires ml_dtypes>=0.4.0, but you have ml-dtypes 0.3.2 which is incompatible.\n",
            "mizani 0.13.5 requires pandas>=2.2.0, but you have pandas 1.5.3 which is incompatible.\n",
            "opencv-python-headless 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n",
            "plotnine 0.14.6 requires pandas>=2.2.0, but you have pandas 1.5.3 which is incompatible.\n",
            "pylibcudf-cu12 25.2.1 requires pyarrow<20.0.0a0,>=14.0.0; platform_machine == \"x86_64\", but you have pyarrow 10.0.1 which is incompatible.\n",
            "tensorflow-decision-forests 1.11.0 requires tensorflow==2.18.0, but you have tensorflow 2.15.1 which is incompatible.\n",
            "tensorflow-text 2.18.1 requires tensorflow<2.19,>=2.18.0, but you have tensorflow 2.15.1 which is incompatible.\n",
            "tf-keras 2.18.0 requires tensorflow<2.19,>=2.18, but you have tensorflow 2.15.1 which is incompatible.\n",
            "thinc 8.3.6 requires numpy<3.0.0,>=2.0.0, but you have numpy 1.26.4 which is incompatible.\n",
            "xarray 2025.3.1 requires pandas>=2.1, but you have pandas 1.5.3 which is incompatible.\n",
            "ydf 0.12.0 requires protobuf<6.0.0,>=5.29.1, but you have protobuf 4.25.8 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed PyMySQL-1.1.2 apache-beam-2.71.0 asn1crypto-1.5.1 beartype-0.22.9 cloud-sql-python-connector-1.20.0 dnspython-2.8.0 envoy-data-plane-0.2.6 fastavro-1.12.1 fasteners-0.20 google-api-python-client-1.12.11 google-apitools-0.5.31 google-cloud-bigtable-2.35.0 google-cloud-dlp-3.34.0 google-cloud-kms-3.10.0 google-cloud-pubsub-2.34.0 google-cloud-pubsublite-1.13.0 google-cloud-recommendations-ai-0.10.18 google-cloud-secret-manager-2.26.0 google-cloud-videointelligence-2.18.0 google-cloud-vision-3.12.0 grpcio-1.65.5 grpcio-status-1.62.3 jsonpickle-3.4.2 keras-2.15.0 ml-dtypes-0.3.2 numpy-1.26.4 objsize-0.7.1 opentelemetry-api-1.39.1 opentelemetry-sdk-1.39.1 opentelemetry-semantic-conventions-0.60b1 overrides-7.7.0 pandas-1.5.3 pg8000-1.31.5 protobuf-4.25.8 pyarrow-10.0.1 pyarrow-hotfix-0.7 pyfarmhash-0.3.2 pymongo-4.16.0 python-tds-1.17.1 requests-2.32.5 scramp-1.4.8 tensorboard-2.15.2 tensorflow-2.15.1 tensorflow-data-validation-1.15.1 tensorflow-estimator-2.15.0 tensorflow-metadata-1.15.0 tensorflow-serving-api-2.15.1 tfx-bsl-1.15.1 uritemplate-3.0.1 wrapt-1.14.2\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "google",
                  "numpy"
                ]
              },
              "id": "b9cf73ab652449848f85c1715a599192"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "current_dir = os.getcwd()\n",
        "if 'notebook' in current_dir:\n",
        "    BASE_DIR = os.path.dirname(current_dir)\n",
        "else:\n",
        "    BASE_DIR = current_dir\n",
        "\n",
        "os.makedirs('data/', exist_ok=True)\n",
        "os.makedirs('results/', exist_ok=True)\n",
        "\n",
        "DATA_DIR = os.path.join(BASE_DIR, \"data/\")\n",
        "RESULTS_DIR = os.path.join(BASE_DIR, \"results/\")\n",
        "TFDV_RESULTS_DIR = os.path.join(RESULTS_DIR, \"tfdv_eval/\")\n",
        "os.makedirs(TFDV_RESULTS_DIR, exist_ok=True)"
      ],
      "metadata": {
        "id": "v8KldJwcemgu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Imports and Directories"
      ],
      "metadata": {
        "id": "K2S2LS4N_646"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import tensorflow_data_validation as tfdv\n",
        "from tensorflow_metadata.proto.v0 import anomalies_pb2\n",
        "\n",
        "BASELINE_CSV = os.path.join(DATA_DIR, \"baseline_data.csv\")\n",
        "CORRUPT_DIR = DATA_DIR"
      ],
      "metadata": {
        "id": "y6FvIE-w_9xH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Helper Functions"
      ],
      "metadata": {
        "id": "-cNr7moi_0s0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# text to simple numeric proxies so TFDV can validate text corruption structurally\n",
        "def add_text_proxies(df: pd.DataFrame) -> pd.DataFrame:\n",
        "    df = df.copy()\n",
        "    if \"text\" not in df.columns:\n",
        "        df[\"text\"] = \"\"\n",
        "\n",
        "    s = df[\"text\"].astype(str).fillna(\"\")\n",
        "\n",
        "    df[\"text_len\"] = s.str.len().astype(np.int64)\n",
        "    df[\"token_count\"] = s.str.split().str.len().fillna(0).astype(np.int64)\n",
        "    df[\"has_empty_text\"] = (s.str.len() == 0).astype(np.int64)\n",
        "\n",
        "    def non_ascii_ratio(text: str) -> float:\n",
        "        if not text:\n",
        "            return 0.0\n",
        "        non_ascii = sum(1 for ch in text if ord(ch) > 127)\n",
        "        return non_ascii / max(1, len(text))\n",
        "\n",
        "    df[\"non_ascii_ratio\"] = s.map(non_ascii_ratio).astype(float)\n",
        "\n",
        "    if \"label\" in df.columns:\n",
        "        df[\"label\"] = pd.to_numeric(df[\"label\"], errors=\"coerce\")\n",
        "\n",
        "    return df\n",
        "\n",
        "def load_csv(path: str) -> pd.DataFrame:\n",
        "    df = pd.read_csv(path)\n",
        "    keep_cols = [c for c in [\"text\", \"label\"] if c in df.columns]\n",
        "    return add_text_proxies(df[keep_cols].copy())\n",
        "\n",
        "def count_anomalies(anomalies: anomalies_pb2.Anomalies) -> dict:\n",
        "    counts = {\n",
        "        \"total\": 0,\n",
        "        \"type\": 0,\n",
        "        \"completeness\": 0,\n",
        "        \"drift\": 0,\n",
        "    }\n",
        "\n",
        "    for _, feat_anom in anomalies.anomaly_info.items():\n",
        "        for reason in feat_anom.reason:\n",
        "            counts[\"total\"] += 1\n",
        "\n",
        "            msg = ((reason.short_description or \"\") + \" \" + (reason.description or \"\")).lower()\n",
        "\n",
        "            if \"type\" in msg:\n",
        "                counts[\"type\"] += 1\n",
        "            if any(k in msg for k in [\"missing\", \"presence\", \"completeness\"]):\n",
        "                counts[\"completeness\"] += 1\n",
        "            if any(k in msg for k in [\"drift\", \"skew\", \"distribution\"]):\n",
        "                counts[\"drift\"] += 1\n",
        "\n",
        "    return counts\n",
        "\n",
        "\n",
        "# severity score for ranking experiments based on heuristics\n",
        "def anomaly_severity_score(counts: dict) -> float:\n",
        "    w_type = 0.30\n",
        "    w_comp = 0.30\n",
        "    w_drift = 0.40\n",
        "\n",
        "    raw = (\n",
        "        w_type * counts[\"type\"] +\n",
        "        w_comp * counts[\"completeness\"] +\n",
        "        w_drift * counts[\"drift\"]\n",
        "    )\n",
        "\n",
        "    return float(1.0 - np.exp(-raw / 3.0))"
      ],
      "metadata": {
        "id": "pDdWHafQ_yfr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Loading baseline data...\")\n",
        "df_baseline = load_csv(BASELINE_CSV)\n",
        "\n",
        "base_stats = tfdv.generate_statistics_from_dataframe(df_baseline)\n",
        "schema = tfdv.infer_schema(base_stats)\n",
        "\n",
        "for feature in [\"text_len\", \"token_count\", \"non_ascii_ratio\", \"has_empty_text\"]:\n",
        "    if feature in schema.feature:\n",
        "        tfdv.set_domain(schema, feature, schema.feature[feature].type)\n",
        "\n",
        "schema_path = os.path.join(TFDV_RESULTS_DIR, \"baseline_schema.pbtxt\")\n",
        "tfdv.write_schema_text(schema, schema_path)\n",
        "\n",
        "# Validate corrupted datasets against baseline\n",
        "results = []\n",
        "\n",
        "corrupt_files = sorted(\n",
        "    f for f in os.listdir(CORRUPT_DIR)\n",
        "    if f.endswith(\".csv\") and f != \"baseline_data.csv\"\n",
        ")\n",
        "\n",
        "print(f\"Found {len(corrupt_files)} corrupted datasets\")\n",
        "\n",
        "for fname in corrupt_files:\n",
        "    exp_name = fname.replace(\".csv\", \"\")\n",
        "    path = os.path.join(CORRUPT_DIR, fname)\n",
        "\n",
        "    df_corrupted = load_csv(path)\n",
        "    cur_stats = tfdv.generate_statistics_from_dataframe(df_corrupted)\n",
        "\n",
        "    anomalies = tfdv.validate_statistics(\n",
        "        statistics=cur_stats,\n",
        "        schema=schema,\n",
        "        previous_statistics=base_stats\n",
        "    )\n",
        "\n",
        "    counts = count_anomalies(anomalies)\n",
        "    score = anomaly_severity_score(counts)\n",
        "\n",
        "    # additional data info (outside TFDV)\n",
        "    base_empty = (df_baseline[\"has_empty_text\"] == 1).mean()\n",
        "    cur_empty = (df_corrupted[\"has_empty_text\"] == 1).mean()\n",
        "\n",
        "    results.append({\n",
        "        \"experiment\": exp_name,\n",
        "        \"n_rows\": int(len(df_corrupted)),\n",
        "        \"n_anomalies_total\": counts[\"total\"],\n",
        "        \"type_violations\": counts[\"type\"],\n",
        "        \"completeness_related\": counts[\"completeness\"],\n",
        "        \"drift_related\": counts[\"drift\"],\n",
        "        \"tfdv_severity_score\": score,\n",
        "        \"delta_empty_text_rate\": float(cur_empty - base_empty),\n",
        "        \"mean_text_len\": float(df_corrupted[\"text_len\"].mean()),\n",
        "        \"mean_token_count\": float(df_corrupted[\"token_count\"].mean()),\n",
        "        \"mean_non_ascii_ratio\": float(df_corrupted[\"non_ascii_ratio\"].mean()),\n",
        "    })\n",
        "\n",
        "    anom_path = os.path.join(TFDV_RESULTS_DIR, f\"anomalies_{exp_name}.pbtxt\")\n",
        "    tfdv.write_anomalies_text(anomalies, anom_path)\n",
        "\n",
        "df_results = pd.DataFrame(results).sort_values(\n",
        "    \"tfdv_severity_score\", ascending=False\n",
        ")\n",
        "\n",
        "out_csv = os.path.join(TFDV_RESULTS_DIR, \"tfdv_analysis.csv\")\n",
        "df_results.to_csv(out_csv, index=False)\n",
        "\n",
        "summary = {\n",
        "    \"n_experiments\": int(len(df_results)),\n",
        "    \"mean_severity_score\": float(df_results[\"tfdv_severity_score\"].mean()) if len(df_results) else None,\n",
        "    \"median_severity_score\": float(df_results[\"tfdv_severity_score\"].median()) if len(df_results) else None,\n",
        "    \"top_3_by_score\": df_results[\n",
        "        [\"experiment\", \"tfdv_severity_score\", \"n_anomalies_total\"]\n",
        "    ].head(3).to_dict(orient=\"records\"),\n",
        "    \"schema_path\": schema_path,\n",
        "    \"results_csv\": out_csv,\n",
        "}\n",
        "\n",
        "with open(os.path.join(TFDV_RESULTS_DIR, \"tfdv_analysis_summary.json\"), \"w\") as f:\n",
        "    json.dump(summary, f, indent=2)\n",
        "\n",
        "print(\"Results saved.\")\n",
        "display(df_results)\n",
        "\n",
        "del df_baseline\n",
        "del df_corrupted"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 405
        },
        "id": "rVgPYH5q869O",
        "outputId": "bc7cb987-5c52-443a-a299-4340458472f0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading baseline data...\n",
            "Found 9 corrupted datasets\n",
            "Results saved.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "                                   experiment  n_rows  n_anomalies_total  \\\n",
              "0                        01_missing_text_data  100000                  1   \n",
              "1                        02_broken_chars_data  100000                  1   \n",
              "2                        03_swapped_text_data  100000                  1   \n",
              "4                      05_swapped_labels_data  100000                  1   \n",
              "5  06_combined_broken_chars_missing_text_data  100000                  1   \n",
              "6           07_combined_swap_text_labels_data  100000                  1   \n",
              "8                     09_all_corruptions_data  100000                  1   \n",
              "3                      04_missing_labels_data  100000                  2   \n",
              "7                       08_heavy_missing_data  100000                  2   \n",
              "\n",
              "   type_violations  completeness_related  drift_related  tfdv_severity_score  \\\n",
              "0                1                     0              0             0.095163   \n",
              "1                1                     0              0             0.095163   \n",
              "2                1                     0              0             0.095163   \n",
              "4                1                     0              0             0.095163   \n",
              "5                1                     0              0             0.095163   \n",
              "6                1                     0              0             0.095163   \n",
              "8                1                     0              0             0.095163   \n",
              "3                0                     0              0             0.000000   \n",
              "7                0                     0              0             0.000000   \n",
              "\n",
              "   delta_empty_text_rate  mean_text_len  mean_token_count  \\\n",
              "0                    0.0      132.54091          25.35594   \n",
              "1                    0.0      188.56445          35.88540   \n",
              "2                    0.0      188.56446          35.88540   \n",
              "4                    0.0      188.56446          35.88540   \n",
              "5                    0.0      173.90968          33.13095   \n",
              "6                    0.0      188.56446          35.88540   \n",
              "8                    0.0      179.27971          34.14421   \n",
              "3                    0.0      188.56446          35.88540   \n",
              "7                    0.0      142.09817          27.14118   \n",
              "\n",
              "   mean_non_ascii_ratio  \n",
              "0              0.002267  \n",
              "1              0.062690  \n",
              "2              0.003194  \n",
              "4              0.003194  \n",
              "5              0.025244  \n",
              "6              0.003194  \n",
              "8              0.020792  \n",
              "3              0.003194  \n",
              "7              0.002348  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-02fc236a-4ce7-4dc7-9dbb-2bbbccdd59b2\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>experiment</th>\n",
              "      <th>n_rows</th>\n",
              "      <th>n_anomalies_total</th>\n",
              "      <th>type_violations</th>\n",
              "      <th>completeness_related</th>\n",
              "      <th>drift_related</th>\n",
              "      <th>tfdv_severity_score</th>\n",
              "      <th>delta_empty_text_rate</th>\n",
              "      <th>mean_text_len</th>\n",
              "      <th>mean_token_count</th>\n",
              "      <th>mean_non_ascii_ratio</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>01_missing_text_data</td>\n",
              "      <td>100000</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.095163</td>\n",
              "      <td>0.0</td>\n",
              "      <td>132.54091</td>\n",
              "      <td>25.35594</td>\n",
              "      <td>0.002267</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>02_broken_chars_data</td>\n",
              "      <td>100000</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.095163</td>\n",
              "      <td>0.0</td>\n",
              "      <td>188.56445</td>\n",
              "      <td>35.88540</td>\n",
              "      <td>0.062690</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>03_swapped_text_data</td>\n",
              "      <td>100000</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.095163</td>\n",
              "      <td>0.0</td>\n",
              "      <td>188.56446</td>\n",
              "      <td>35.88540</td>\n",
              "      <td>0.003194</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>05_swapped_labels_data</td>\n",
              "      <td>100000</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.095163</td>\n",
              "      <td>0.0</td>\n",
              "      <td>188.56446</td>\n",
              "      <td>35.88540</td>\n",
              "      <td>0.003194</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>06_combined_broken_chars_missing_text_data</td>\n",
              "      <td>100000</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.095163</td>\n",
              "      <td>0.0</td>\n",
              "      <td>173.90968</td>\n",
              "      <td>33.13095</td>\n",
              "      <td>0.025244</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>07_combined_swap_text_labels_data</td>\n",
              "      <td>100000</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.095163</td>\n",
              "      <td>0.0</td>\n",
              "      <td>188.56446</td>\n",
              "      <td>35.88540</td>\n",
              "      <td>0.003194</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>09_all_corruptions_data</td>\n",
              "      <td>100000</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.095163</td>\n",
              "      <td>0.0</td>\n",
              "      <td>179.27971</td>\n",
              "      <td>34.14421</td>\n",
              "      <td>0.020792</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>04_missing_labels_data</td>\n",
              "      <td>100000</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>188.56446</td>\n",
              "      <td>35.88540</td>\n",
              "      <td>0.003194</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>08_heavy_missing_data</td>\n",
              "      <td>100000</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>142.09817</td>\n",
              "      <td>27.14118</td>\n",
              "      <td>0.002348</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-02fc236a-4ce7-4dc7-9dbb-2bbbccdd59b2')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-02fc236a-4ce7-4dc7-9dbb-2bbbccdd59b2 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-02fc236a-4ce7-4dc7-9dbb-2bbbccdd59b2');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-60b68334-8130-4dc9-800d-785998eec2fb\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-60b68334-8130-4dc9-800d-785998eec2fb')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-60b68334-8130-4dc9-800d-785998eec2fb button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "  <div id=\"id_79afc41a-766d-4b3f-bc69-e1485b95967d\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df_results')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_79afc41a-766d-4b3f-bc69-e1485b95967d button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df_results');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df_results",
              "summary": "{\n  \"name\": \"df_results\",\n  \"rows\": 9,\n  \"fields\": [\n    {\n      \"column\": \"experiment\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 9,\n        \"samples\": [\n          \"04_missing_labels_data\",\n          \"02_broken_chars_data\",\n          \"07_combined_swap_text_labels_data\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"n_rows\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 100000,\n        \"max\": 100000,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          100000\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"n_anomalies_total\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 1,\n        \"max\": 2,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          2\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"type_violations\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"completeness_related\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 0,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"drift_related\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 0,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"tfdv_severity_score\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.041962754332608564,\n        \"min\": 0.0,\n        \"max\": 0.09516258196404037,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"delta_empty_text_rate\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0,\n        \"min\": 0.0,\n        \"max\": 0.0,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"mean_text_len\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 21.85943816505495,\n        \"min\": 132.54091,\n        \"max\": 188.56446,\n        \"num_unique_values\": 6,\n        \"samples\": [\n          132.54091\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"mean_token_count\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 4.1105661025463105,\n        \"min\": 25.35594,\n        \"max\": 35.8854,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          35.8854\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"mean_non_ascii_ratio\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.020259966691330473,\n        \"min\": 0.0022673985465371527,\n        \"max\": 0.062689575299362,\n        \"num_unique_values\": 7,\n        \"samples\": [\n          0.0022673985465371527\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        }
      ]
    }
  ]
}